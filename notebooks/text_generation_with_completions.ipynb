{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "379fa59e",
   "metadata": {},
   "source": [
    "# üöÄ Text Generation Apps using Python (Completions Only)\n",
    "\n",
    "This notebook showcases **14 text generation use cases** using OpenAI **Completions API**.  \n",
    "Each section includes a description, the Python code, and expected output.\n",
    "\n",
    "---\n",
    "\n",
    "## üìë Table of Contents\n",
    "1. [Summarization](#-Use-Case-1-Summarization)  \n",
    "2. [Sentiment Classification](#-Use-Case-2-Sentiment-Classification)  \n",
    "3. [Multilingual Generation + Translation](#-Use-Case-3-Multilingual-Generation--Translation)  \n",
    "4. [Semantic Interpretation of Idiom](#-Use-Case-4-Semantic-Interpretation-of-Idiom)  \n",
    "5. [Factual Recall / Explanatory Response](#-Use-Case-5-Factual-Recall--Explanatory-Response)  \n",
    "6. [Code Generation & Explanation](#-Use-Case-6-Code-Generation--Explanation)  \n",
    "7. [Conversational Agent (FAQ Assistant)](#-Use-Case-7-Conversational-Agent-FAQ-Assistant)  \n",
    "8. [Style Transfer / Tone Adaptation](#-Use-Case-8-Style-Transfer--Tone-Adaptation)  \n",
    "9. [Data-to-Text Generation](#-Use-Case-9-Data-to-Text-Generation)  \n",
    "10. [Creative Writing](#-Use-Case-10-Creative-Writing)  \n",
    "11. [Question Generation](#-Use-Case-11-Question-Generation)  \n",
    "12. [Entity Extraction with Explanation](#-Use-Case-12-Entity-Extraction-with-Explanation)  \n",
    "13. [Paraphrasing / Rewriting](#-Use-Case-13-Paraphrasing--Rewriting)  \n",
    "14. [Email / Document Drafting](#-Use-Case-14-Email--Document-Drafting)  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cfbf4a",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Load environment variables (OPENAI_API_KEY) using python-dotenv.\n",
    "\n",
    "Create a helper function get_completion(prompt) that calls the OpenAI Completions API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1034991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (skip if already installed)\n",
    "# %pip install openai tiktoken python-dotenv\n",
    "\n",
    "import os\n",
    "import logging\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from typing import Optional\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Setup logging (INFO by default, DEBUG for detailed traces)\n",
    "# -------------------------------------------------------------------\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Load environment variables\n",
    "# -------------------------------------------------------------------\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OPENAI_API_KEY is not set in environment or .env file\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Initialize OpenAI client\n",
    "# -------------------------------------------------------------------\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Helper function for completions API\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def get_completion(\n",
    "    prompt: str,\n",
    "    model: str = \"gpt-3.5-turbo-instruct\",\n",
    "    max_tokens: int = 200,\n",
    "    temperature: float = 0.7,\n",
    "    log_response: bool = False\n",
    ") -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Get a text completion from OpenAI API.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The input prompt.\n",
    "        model (str): Model name (default: gpt-3.5-turbo-instruct).\n",
    "        max_tokens (int): Maximum tokens to generate.\n",
    "        temperature (float): Randomness level (0 = deterministic, 1 = creative).\n",
    "        log_response (bool): Whether to log full response for debugging.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated text completion, or None if error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.completions.create(\n",
    "            model=model,\n",
    "            prompt=prompt,\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        if log_response:\n",
    "            logger.debug(f\"Full API response: {response}\")\n",
    "\n",
    "        return response.choices[0].text.strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error during completion request: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Example usage\n",
    "# -------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    test_prompt = \"Write a haiku about AI and the future.\"\n",
    "    result = get_completion(test_prompt, log_response=True)\n",
    "\n",
    "    if result:\n",
    "        print(\"‚úÖ Completion result:\\n\", result)\n",
    "    else:\n",
    "        print(\"‚ùå No response received.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221d9864",
   "metadata": {},
   "source": [
    "## ‚úÖ Use Case 1: Summarization\n",
    "**Input:**  \n",
    "Sparse vector feature indexing allows scalable search over events by turning categorical attributes into an extremely wide, mostly empty vector...\n",
    "\n",
    "**Sample Output:**  \n",
    "\"It converts categorical features into sparse vectors for scalable search. The trade-off is efficiency vs. memory/compute cost at high cardinality.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2904a9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Use Case 1: Summarization Code\n",
    "\n",
    "technical_paragraph = \"\"\"\n",
    "Sparse vector feature indexing allows scalable search over events by turning \n",
    "categorical attributes into an extremely wide, mostly empty vector. Each distinct \n",
    "token (e.g. event_type:click, browser:mobile) maps to a coordinate set to 1 while \n",
    "all others remain 0. This removes unintended ordering between categories and keeps \n",
    "distance metrics meaningful, but at very high cardinality memory and compute \n",
    "overhead grow rapidly, motivating hashing tricks or learned embeddings.\n",
    "\"\"\".strip()\n",
    "\n",
    "summary_prompt = f\"Summarize the following paragraph in 2 crisp sentences focusing on purpose and trade-offs:\\n\\n{technical_paragraph}\\n\\nSummary:\"\n",
    "\n",
    "# Call completions API using helper\n",
    "summary = get_completion(\n",
    "    summary_prompt, model=\"gpt-3.5-turbo-instruct\", max_tokens=120, temperature=0.4)\n",
    "\n",
    "print(\"‚úÖ Summary:\", summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c7a222",
   "metadata": {},
   "source": [
    "## ‚úÖ Use Case 2: Sentiment Classification\n",
    "**Input:**  \n",
    "\"The user interface feels sluggish, but the reporting features are fantastic.\"\n",
    "\n",
    "**Sample Output:**  \n",
    "\"Neutral\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e3576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Use Case 2: Sentiment Classification (Multiple Inputs)\n",
    "\n",
    "# Sample inputs\n",
    "input_texts = [\n",
    "    \"The user interface feels sluggish, but the reporting features are fantastic.\",  # Neutral\n",
    "    \"I love the new dashboard design, it‚Äôs clean and very intuitive.\",               # Positive\n",
    "    \"The system keeps crashing frequently, making it hard to use.\"                   # Negative\n",
    "]\n",
    "\n",
    "# Loop through each input and classify sentiment\n",
    "for input_text in input_texts:\n",
    "    sentiment_prompt = f\"\"\"\n",
    "    Classify the sentiment of the following text strictly as Positive, Negative, or Neutral.\n",
    "    If the text contains both positive and negative aspects, classify it as Neutral.\n",
    "\n",
    "    Text: \"{input_text}\"\n",
    "\n",
    "    Sentiment:\n",
    "    \"\"\"\n",
    "\n",
    "    # Call completions API using helper\n",
    "    sentiment = get_completion(\n",
    "        sentiment_prompt,\n",
    "        model=\"gpt-3.5-turbo-instruct\",\n",
    "        max_tokens=20,\n",
    "        temperature=0  # deterministic output\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ Text: {input_text}\")\n",
    "    print(f\"‚úÖ Sentiment: {sentiment.strip()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c6fc11",
   "metadata": {},
   "source": [
    "## ‚úÖ Use Case 3: Multilingual Generation + Translation\n",
    "**Input:**  \n",
    "\"Artificial Intelligence will transform education.\"\n",
    "\n",
    "**Sample Output:**  \n",
    "- French: \"L'intelligence artificielle transformera l'√©ducation.\"  \n",
    "- Spanish: \"La inteligencia artificial transformar√° la educaci√≥n.\"  \n",
    "- Hindi: \"‡§ï‡•É‡§§‡•ç‡§∞‡§ø‡§Æ ‡§¨‡•Å‡§¶‡•ç‡§ß‡§ø‡§Æ‡§§‡•ç‡§§‡§æ ‡§∂‡§ø‡§ï‡•ç‡§∑‡§æ ‡§ï‡•ã ‡§¨‡§¶‡§≤ ‡§¶‡•á‡§ó‡•Ä‡•§\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56b1e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ Use Case 3: Multilingual Generation + Translation\n",
    "\n",
    "input_text = \"Artificial Intelligence will transform education.\"\n",
    "languages = [\"French\", \"Spanish\", \"Hindi\"]\n",
    "\n",
    "for lang in languages:\n",
    "    translation_prompt = f\"Translate the following text into {lang}:\\n\\n{input_text}\"\n",
    "    translation = get_completion(\n",
    "        translation_prompt, max_tokens=60, temperature=0.3)\n",
    "    print(f\"‚úÖ {lang}: {translation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1177ce",
   "metadata": {},
   "source": [
    "## ‚úÖ Use Case 4: Semantic Interpretation of Idiom\n",
    "**Input:**  \n",
    "\"Kick the bucket\"\n",
    "\n",
    "**Sample Output:**  \n",
    "\"It means someone has died.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450e8e44",
   "metadata": {},
   "source": [
    "## ‚úÖ Use Case 5: Factual Recall / Explanatory Response\n",
    "**Input:**  \n",
    "\"Why is the sky blue?\"\n",
    "\n",
    "**Sample Output:**  \n",
    "\"The sky looks blue because sunlight is scattered by air molecules. Blue light is scattered more strongly than other colors, so we mostly see blue.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3663aa09",
   "metadata": {},
   "source": [
    "## ‚úÖ Use Case 6: Code Generation & Explanation\n",
    "**Input:**  \n",
    "\"Write a Python function that checks if a number is prime.\"\n",
    "\n",
    "**Sample Output:**  \n",
    "```python\n",
    "def is_prime(n):\n",
    "    if n < 2:\n",
    "        return False\n",
    "    for i in range(2, int(n**0.5) + 1):\n",
    "        if n % i == 0:\n",
    "            return False\n",
    "    return True\n",
    "````\n",
    "\n",
    "**Explanation:**\n",
    "\"The function checks divisibility from 2 up to ‚àön. If any divisor is found, it returns False; otherwise, True.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e6919f",
   "metadata": {},
   "source": [
    "## ‚úÖ Use Case 7: Conversational Agent (FAQ Assistant)\n",
    "\n",
    "**Input:**\n",
    "\"What is the purpose of Git?\"\n",
    "\n",
    "**Sample Output:**\n",
    "\"Git is a version control system that tracks changes in code, helps collaboration, and manages project history.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7da3675",
   "metadata": {},
   "source": [
    "\n",
    "## ‚úÖ Use Case 8: Style Transfer / Tone Adaptation\n",
    "\n",
    "**Input:**\n",
    "\"Please confirm receipt of this document at the earliest.\"\n",
    "\n",
    "**Sample Output:**\n",
    "\"Hey, just let me know when you get this doc!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb220da",
   "metadata": {},
   "source": [
    "## ‚úÖ Use Case 9: Data-to-Text Generation\n",
    "\n",
    "**Input:**\n",
    "Region: North\n",
    "Sales: \\$50,000\n",
    "Increase: 10%\n",
    "\n",
    "**Sample Output:**\n",
    "\"The North region generated \\$50,000 in sales, reflecting a 10% increase compared to the previous period.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f58db56",
   "metadata": {},
   "source": [
    "## ‚úÖ Use Case 10: Creative Writing\n",
    "\n",
    "**Input:**\n",
    "\"A robot learning to paint\"\n",
    "\n",
    "**Sample Output:**\n",
    "\"The robot dipped its brush in bright colors, each stroke a clumsy attempt at beauty. Slowly, it learned to create sunsets and flowers. Its creators realized the machine had found its soul in art.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd24c6a",
   "metadata": {},
   "source": [
    "## ‚úÖ Use Case 11: Question Generation\n",
    "\n",
    "**Input:**\n",
    "\"The Pacific Ocean is the largest and deepest of Earth's oceanic divisions. It extends from the Arctic Ocean in the north to the Southern Ocean in the south.\"\n",
    "\n",
    "**Sample Output:**\n",
    "\n",
    "1. What is the largest ocean on Earth?\n",
    "2. How deep is the Pacific Ocean compared to other oceans?\n",
    "3. Which oceans border the Pacific to the north and south?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f37ea55",
   "metadata": {},
   "source": [
    "## ‚úÖ Use Case 12: Entity Extraction with Explanation\n",
    "\n",
    "**Input:**\n",
    "\"Apple announced a new partnership with Tesla to develop AI-powered batteries in California.\"\n",
    "\n",
    "**Sample Output:**\n",
    "\n",
    "* **Apple** ‚Äì Technology company forming a partnership.\n",
    "* **Tesla** ‚Äì Automotive/energy company collaborating on batteries.\n",
    "* **California** ‚Äì Location where the initiative is happening."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2395e279",
   "metadata": {},
   "source": [
    "## ‚úÖ Use Case 13: Paraphrasing / Rewriting\n",
    "\n",
    "**Input:**\n",
    "\"The proliferation of interconnected devices has exponentially increased the complexity of ensuring cybersecurity across distributed networks.\"\n",
    "\n",
    "**Sample Output:**\n",
    "\"With more connected devices, keeping networks secure has become much harder.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae01be8",
   "metadata": {},
   "source": [
    "\n",
    "## ‚úÖ Use Case 14: Email / Document Drafting\n",
    "\n",
    "**Input:**\n",
    "\"Announce a team meeting for Friday at 3 PM to discuss the quarterly results.\"\n",
    "\n",
    "**Sample Output:**\n",
    "\"Subject: Team Meeting ‚Äì Friday at 3 PM\n",
    "Hi Team,\n",
    "We will have a meeting on Friday at 3 PM to review our quarterly results. Please make sure to attend.\n",
    "Best regards,\n",
    "\\[Your Name]\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
